{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import capstone\n",
    "import keystone\n",
    "import shutil\n",
    "import struct\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_idx_dict(names):\n",
    "    d = {} \n",
    "    for i, n in enumerate(names):\n",
    "        d[n] = i\n",
    "\n",
    "    return d\n",
    "\n",
    "def two_way_dict(dictionary):\n",
    "    for k in list(dictionary.keys()):\n",
    "        dictionary[dictionary[k]] = k\n",
    "\n",
    "    return dictionary\n",
    "\n",
    "def dict_safe_get(dictionary, key):\n",
    "    try:\n",
    "        return dictionary[key]\n",
    "    except KeyError:\n",
    "        if isinstance(key, str):\n",
    "            return 0\n",
    "        else:\n",
    "            return 'UNKNOWN'\n",
    "        \n",
    "def expand_rt_dict(dictionary):\n",
    "    for k in list(dictionary.keys()):\n",
    "        if k[0] == 'x':\n",
    "            rx_pattern = re.compile(r'r(\\d)+', 0)\n",
    "            val = dictionary[k]\n",
    "\n",
    "            if rx_pattern.search(val):\n",
    "                val += 'd'\n",
    "            else:\n",
    "                val = 'e' + val[1:]\n",
    "\n",
    "            dictionary['w' + k[1:]] = val\n",
    "\n",
    "    dictionary['xzr'] = 0\n",
    "    dictionary['wzr'] = 0\n",
    "\n",
    "    reg_p = '('\n",
    "    for k in dictionary.keys():\n",
    "        reg_p += k + '|'\n",
    "    reg_p = reg_p[:-1] + ')'\n",
    "\n",
    "    # for k,v in dictionary.items():\n",
    "        # print(k,v)\n",
    "\n",
    "    return reg_p, dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Const:\n",
    "    HEADER_SIZE = 64 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElfHeader:\n",
    "    unpacked_data = None\n",
    "\n",
    "    fields = [\n",
    "        \"e_ident\",\n",
    "        \"e_type\",\n",
    "        \"e_machine\",\n",
    "        \"e_version\",\n",
    "        \"e_entry\",\n",
    "        \"e_phoff\",\n",
    "        \"e_shoff\",\n",
    "        \"e_flags\",\n",
    "        \"e_ehsize\",\n",
    "        \"e_phentsize\",\n",
    "        \"e_phnum\",\n",
    "        \"e_shentsize\",\n",
    "        \"e_shnum\",\n",
    "        \"e_shstrndx\",\n",
    "    ]\n",
    "\n",
    "    idx_dict = make_idx_dict(fields)\n",
    "\n",
    "    format = (\n",
    "        # e_ident (16 bytes), e_type (2 bytes), e_machine (2 bytes), e_version (4 bytes)\n",
    "        '< 16s H H I' +\n",
    "        # e_entry (8 bytes), e_phoff (8 bytes), e_shoff (8 bytes), e_flags (4 bytes)\n",
    "        'Q Q Q I' +\n",
    "        # e_ehsize (2 bytes), e_phentsize (2 bytes), e_phnum (2 bytes), e_shentsize (2 bytes)\n",
    "        'H H H H' +\n",
    "        # e_shnum (2 bytes), e_shstrndx (2 bytes)\n",
    "        'H H'\n",
    "    )\n",
    "\n",
    "    def print():\n",
    "        for i, f in enumerate(ElfHeader.fields):\n",
    "            print(f'{f}: {ElfHeader.unpacked_data[i]}')\n",
    "    \n",
    "    def read_elf_header():\n",
    "        if ElfFile.data[:4] != b'\\x7fELF':\n",
    "            raise ValueError(\"Not a valid ELF file.\")\n",
    "        \n",
    "        ElfHeader.unpacked_data = list(struct.unpack(ElfHeader.format, ElfFile.data[:Const.HEADER_SIZE]))\n",
    "\n",
    "    def overwrite_elf_header(file_path):\n",
    "        amd_machine = 0x003e\n",
    "        ElfHeader.unpacked_data[2] = amd_machine\n",
    "\n",
    "        packed_data = struct.pack(ElfHeader.format, *ElfHeader.unpacked_data)\n",
    "\n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(packed_data)\n",
    "            f.write(ElfFile.data[Const.HEADER_SIZE:])\n",
    "\n",
    "    def get(name):\n",
    "        idx = ElfHeader.idx_dict[name]\n",
    "        return ElfHeader.unpacked_data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SectionHeader:\n",
    "    delete_pattern = \\\n",
    "        re.compile(r'(.note.gnu.property|.eh.frame)', 0)\n",
    "\n",
    "    sh_types = two_way_dict({\n",
    "        'SHT_NULL' : 0, \n",
    "        'SHT_PROGBITS' : 1, \n",
    "        'SHT_SYMTAB' : 2, \n",
    "        'SHT_STRTAB' : 3, \n",
    "        'SHT_RELA' : 4, \n",
    "        'SHT_HASH' : 5, \n",
    "        'SHT_DYNAMIC' : 6, \n",
    "        'SHT_NOTE' : 7, \n",
    "        'SHT_NOBITS' : 8, \n",
    "    })\n",
    "\n",
    "    fields = [\n",
    "        \"sh_name\",      # Section name (index into section header string table)\n",
    "        \"sh_type\",      # Section type\n",
    "        \"sh_flags\",     # Section attributes\n",
    "        \"sh_addr\",      # Virtual address in memory\n",
    "        \"sh_offset\",    # Offset in file\n",
    "        \"sh_size\",      # Size of section\n",
    "        \"sh_link\",      # Link to other section\n",
    "        \"sh_info\",      # Miscellaneous information\n",
    "        \"sh_addralign\", # Address alignment boundary\n",
    "        \"sh_entsize\"    # Size of entries, if section has table\n",
    "    ]\n",
    "\n",
    "    format = (\n",
    "        # sh_name (4 bytes), sh_type (4 bytes), sh_flags (8 bytes), sh_addr (8 bytes)\n",
    "        '< I I Q Q' +  \n",
    "        # sh_offset (8 bytes), sh_size (8 bytes), sh_link (4 bytes), sh_info (4 bytes)\n",
    "        'Q Q I I' +    \n",
    "        # sh_addralign (8 bytes), sh_entsize (8 bytes)\n",
    "        'Q Q' \n",
    "    )\n",
    "\n",
    "    idx_dict = make_idx_dict(fields)\n",
    "\n",
    "    shstroff = None\n",
    "    \n",
    "    def __init__(self, offset, verbose = False):\n",
    "        self.unpacked_data = list(\n",
    "            struct.unpack(\n",
    "                SectionHeader.format, \n",
    "                ElfFile.data[offset : offset + ElfHeader.get('e_shentsize')],\n",
    "            )\n",
    "        )\n",
    "\n",
    "        sh_off = self.get('sh_offset')\n",
    "        self.section_data = ElfFile.data[sh_off : sh_off + self.get('sh_size')]\n",
    "        self.type = SectionHeader.sh_types[self.get('sh_type')]\n",
    "\n",
    "        self.name = None\n",
    "\n",
    "        if verbose:\n",
    "            self.print()\n",
    "\n",
    "    def print(self):\n",
    "        for i, f in enumerate(SectionHeader.fields):\n",
    "            print(f'{f}: {self.unpacked_data[i]}')\n",
    "        print(self.type)\n",
    "\n",
    "    def get(self, name):\n",
    "        idx = SectionHeader.idx_dict[name]\n",
    "        return self.unpacked_data[idx]\n",
    "    \n",
    "    def set_name(self, verbose = False):\n",
    "        self.name = ElfFile.find_string(self.get('sh_name'), True)\n",
    "\n",
    "        if verbose:\n",
    "            print(self.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sym:\n",
    "    size = 0x18\n",
    "\n",
    "    format = (\n",
    "        # st_name(4 bytes), st_info(1 byte), st_other(1 byte)\n",
    "        '< I B B' +\n",
    "        # st_shndx(2 bytes), st_value(8 bytes), st_size(8 bytes)\n",
    "        'H Q Q'\n",
    "    )\n",
    "\n",
    "    fields = [\n",
    "        'st_name',\n",
    "        'st_info',\n",
    "        'st_other',\n",
    "        'st_shndx',\n",
    "        'st_value',\n",
    "        'st_size',\n",
    "    ]\n",
    "\n",
    "    stbsym = two_way_dict({\n",
    "        'STB_LOCAL' : 0,\n",
    "        'STB_GLOBAL' : 1,\n",
    "        'STB_WEAK' : 2,\n",
    "    })\n",
    "\n",
    "    sttsym = two_way_dict({\n",
    "        'STT_NOTYPE' : 0,\n",
    "        'STT_OBJECT' : 1,\n",
    "        'STT_FUNC' : 2,\n",
    "        'STT_SECTION' : 3,\n",
    "        'STT_FILE' : 4,\n",
    "    })\n",
    "        \n",
    "    idx_dict = make_idx_dict(fields)\n",
    "\n",
    "    def __init__(self, offset, verbose = False):\n",
    "        self.unpacked_data = struct.unpack(Sym.format, ElfFile.data[offset : offset + Sym.size])\n",
    "        self.offset = offset\n",
    "\n",
    "        self.name = ElfFile.find_string(self.get('st_name'), sh_string = False)\n",
    "        self.binding, self.type = Sym.get_binding_and_type(self.get('st_info'))\n",
    "\n",
    "        if(verbose):\n",
    "            self.print()\n",
    "\n",
    "    def get_binding_and_type(st_info):\n",
    "        binding = (st_info >> 4) & 0xF  \n",
    "        symbol_type = st_info & 0xF\n",
    "        \n",
    "        return dict_safe_get(Sym.stbsym, binding), dict_safe_get(Sym.sttsym, symbol_type)\n",
    "\n",
    "    def print(self):\n",
    "        for i, f in enumerate(Sym.fields):\n",
    "            print(f'{f}: {self.unpacked_data[i]}')\n",
    "\n",
    "        print(self.name, self.binding, self.type)\n",
    "\n",
    "    def overwrite_sym(self, offset):\n",
    "        pass\n",
    "\n",
    "    def get(self, name):\n",
    "        idx = Sym.idx_dict[name]\n",
    "        return self.unpacked_data[idx]\n",
    "\n",
    "    def collect_sym_entries(sh):\n",
    "        base_offset = offset = sh.get('sh_offset')\n",
    "        size = sh.get('sh_size')\n",
    "        entsize = sh.get('sh_entsize')\n",
    "        sym_entries = []\n",
    "\n",
    "        while offset < base_offset + size:\n",
    "            sym_entries += [Sym(offset)]\n",
    "            offset += entsize\n",
    "\n",
    "        return sym_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rela:\n",
    "    code_types = two_way_dict({\n",
    "        'R_AARCH64_CALL26' : 283,\n",
    "        'R_AARCH64_ADD_ABS_LO12_NC' : 277,\t\n",
    "        'R_AARCH64_ADR_PREL_PG_HI21' : 275,\n",
    "        'R_AARCH64_ABS64' : 257,\n",
    "        # not overlapping, so i keep it in the same dict\n",
    "        'R_AMD64_64' : 1,\n",
    "        'R_AMD64_PC32' : 2,\n",
    "        'R_AMD64_32' : 10,\n",
    "    })\n",
    "\n",
    "    size = 0x18\n",
    "\n",
    "    format = '<QQq'  # r_offset, r_info, r_addend\n",
    "\n",
    "    fields = ['r_offset', 'r_info', 'r_addend']\n",
    "\n",
    "    idx_dict = make_idx_dict(fields)\n",
    "\n",
    "    #define ELF64_R_SYM(i)((i) >> 32)\n",
    "    def R_SYM(i):\n",
    "        return i >> 32\n",
    "    \n",
    "    #define ELF64_R_TYPE(i)((i) & 0xf f f f f f f f L)\n",
    "    def R_TYPE(i):\n",
    "        return i & 0xffffffff\n",
    "\n",
    "    #define ELF64_R_INFO(s, t)(((s) << 32) + ((t) & 0xf f f f f f f f L))\n",
    "    def R_INFO(s, t):\n",
    "        return (s << 32) + (t & 0xffffffff)\n",
    "\n",
    "    def __init__(self, offset, verbose = False):\n",
    "        self.unpacked_data = list(\n",
    "            struct.unpack(Rela.format, ElfFile.data[offset : offset + Rela.size])\n",
    "        )\n",
    "        self.offset = offset\n",
    "        info = self.get('r_info')\n",
    "        self.sym = Rela.R_SYM(info)\n",
    "        self.type = Rela.code_types[Rela.R_TYPE(info)]\n",
    "\n",
    "        if verbose:\n",
    "            self.print()\n",
    "\n",
    "    def print(self):\n",
    "        for i, f in enumerate(Rela.fields):\n",
    "            print(f'{f}: {self.unpacked_data[i]}')\n",
    "\n",
    "        print(f'{self.sym=}')\n",
    "        print(f'{self.type=}')\n",
    "\n",
    "    def overwrite_rela(\n",
    "            self, \n",
    "            offset = None, \n",
    "            symbol = None, \n",
    "            type = None, \n",
    "            addend = None,\n",
    "        ):\n",
    "        if offset:\n",
    "            self.unpacked_data[0] = offset\n",
    "        if symbol:\n",
    "            self.sym = symbol\n",
    "        if type:\n",
    "            self.type = type \n",
    "        if addend:\n",
    "            self.unpacked_data[2] = addend\n",
    "\n",
    "        self.unpacked_data[1] = Rela.R_INFO(self.sym, Rela.code_types[type])\n",
    "        \n",
    "    def get(self, name):\n",
    "        idx = Rela.idx_dict[name]\n",
    "        return self.unpacked_data[idx]\n",
    "\n",
    "    def collect_rela_entries(sh):\n",
    "        base_offset = offset = sh.get('sh_offset')\n",
    "        size = sh.get('sh_size')\n",
    "        entsize = sh.get('sh_entsize')\n",
    "        rela_entries = {}\n",
    "\n",
    "        while offset < base_offset + size:\n",
    "            rela = Rela(offset)\n",
    "            rela_entries[rela.get('r_offset')] = rela\n",
    "            offset += entsize\n",
    "\n",
    "        return rela_entries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Comparator:\n",
    "    # for capstone output\n",
    "    hex_pattern = '(0x[0-9a-f]+)' \n",
    "\n",
    "    prolog = \"\"\"\n",
    "        stp x29, x30, [sp, #-prologue_shift]!\n",
    "        mov x29, sp\n",
    "    \"\"\"\n",
    "\n",
    "    epilog = \"\"\"\n",
    "        ldp x29, x30, [sp], #prologue_shift\n",
    "        ret\n",
    "    \"\"\"\n",
    "\n",
    "    escape_chars = '[]'\n",
    "\n",
    "    def unify(text, pattern = False):\n",
    "        if pattern:\n",
    "            for char in Comparator.escape_chars:\n",
    "                text = text.replace(f'{char}', fr'\\{char}')\n",
    "\n",
    "        text = text.replace('prologue_shift', Comparator.hex_pattern)\n",
    "\n",
    "        tokens = text.strip().split()\n",
    "\n",
    "        unified = ''\n",
    "        for t in tokens:\n",
    "            unified += t + ' '\n",
    "\n",
    "        return unified \n",
    "    \n",
    "    def compare_part(code, is_prolog = True, verbose = False):\n",
    "        unified_code = Comparator.unify(code)\n",
    "\n",
    "        pattern = getattr(Comparator, 'prolog' if is_prolog else 'epilog')\n",
    "        unified_pattern = Comparator.unify(pattern, True)\n",
    "\n",
    "        if verbose: \n",
    "            print(unified_code)\n",
    "            print(unified_pattern)\n",
    "\n",
    "        compiled_pattern = re.compile(unified_pattern, re.IGNORECASE)\n",
    "        return compiled_pattern.search(unified_code)\n",
    "\n",
    "    # def count_lines(chars, code, from_end = False):\n",
    "    #     lengths = []\n",
    "    #     for line in code.splitlines():\n",
    "    #         length = 0\n",
    "    #         for word in line.split():\n",
    "    #             length += len(word)\n",
    "    #         lengths += [length]\n",
    "\n",
    "    #     lengths = reversed(lengths) if from_end else lengths\n",
    "\n",
    "    #     lines = 0\n",
    "    #     for l in lengths:\n",
    "    #         if chars == 0:\n",
    "    #             return lines\n",
    "\n",
    "    #         chars -= l\n",
    "    #         lines += 1\n",
    "\n",
    "    #     assert False, 'Function detection failed'\n",
    "\n",
    "    def check_function(code):\n",
    "        match_p = Comparator.compare_part(code, True)\n",
    "        match_e = Comparator.compare_part(code, False)\n",
    "\n",
    "        if match_p and match_e:\n",
    "            span = (match_p.span()[0], match_e.span()[1])\n",
    "\n",
    "            assert match_p.group(1) == match_p.group(1), \"Prologue shift doesn't match\"\n",
    "\n",
    "            if span == (0, len(code) - 1):\n",
    "                return match_p.group(1) \n",
    "\n",
    "            assert False, (span(), len(code) - 1, 'Assignment conditions not fullfilled.')\n",
    "            \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translator:\n",
    "    prolog_x86 = \"\"\"\n",
    "    push rbp\n",
    "    mov rbp, rsp\n",
    "    sub rsp, #prologue_shift\n",
    "    \"\"\"\n",
    "\n",
    "    epilog_x86 = \"\"\"\n",
    "    mov rax, rdi\n",
    "    leave\n",
    "    ret\n",
    "    \"\"\"\n",
    "\n",
    "    def count_functions(code_section):\n",
    "        code = Translator.disassemble_code(code_section, show_offsets = False)\n",
    "        return Comparator.check_function(code)\n",
    "\n",
    "    def disassemble_code(code_section, show_offsets = True, verbose = False):\n",
    "        # AArch64 architecture\n",
    "        md = capstone.Cs(capstone.CS_ARCH_ARM64, capstone.CS_MODE_ARM)\n",
    "        instructions = md.disasm(code_section, 0)\n",
    "\n",
    "        code = \"\"\n",
    "        for insn in instructions:\n",
    "            off = f\"0x{insn.address:x}:\\t\" if show_offsets else \"\"\n",
    "            code_line = f\"{off}{insn.mnemonic}\\t{insn.op_str}\"\n",
    "\n",
    "            code += code_line + \"\\n\"\n",
    "\n",
    "            if verbose:\n",
    "                print(code_line)\n",
    "        \n",
    "        return code\n",
    "    \n",
    "    def translate_code(code_section, p_shift, rela_section = None):\n",
    "        code = Translator.disassemble_code(code_section, True).splitlines()\n",
    "        code_x86 = Translator.prolog_x86.replace('#prologue_shift', p_shift)\n",
    "\n",
    "        md = capstone.Cs(capstone.CS_ARCH_ARM64, capstone.CS_MODE_ARM)\n",
    "        md.detail = True\n",
    "        instructions = md.disasm(code_section, 0)\n",
    "\n",
    "        fields = [\n",
    "        'address', 'bytes', 'errno', 'group', 'group_name', 'groups', 'id',\n",
    "        'insn_name', 'mnemonic', 'op_count', 'op_find', 'op_str', 'reg_name',\n",
    "        'reg_read', 'reg_write', 'regs_access', 'regs_read', 'regs_write', 'size'\n",
    "        ]\n",
    "\n",
    "        inst_list = []\n",
    "        for insn in instructions:\n",
    "            inst_list += [insn]\n",
    "\n",
    "        for insn in inst_list[2:-2]:\n",
    "            off = f\"0x{insn.address:x}:\\t\" \n",
    "\n",
    "            code_line = f\"{off}{insn.mnemonic}\\t{insn.op_str}\"\n",
    "            code_line_x86 = ParseInsn.parse(insn, rela_section)\n",
    "\n",
    "            code += code_line + \"\\n\"\n",
    "            code_x86 += code_line_x86 \n",
    "\n",
    "            print(code_line)\n",
    "            print(code_line_x86)\n",
    "\n",
    "            # print(ParseInsn.parse(insn, rela_section))\n",
    "\n",
    "        return code_x86 + Translator.epilog_x86\n",
    "\n",
    "    def assemble_code(code):\n",
    "        # separate assembly instructions by ; or \\n\n",
    "        CODE = b\"INC ecx; DEC edx\"\n",
    "        \n",
    "        try:\n",
    "            ks = keystone.Ks(keystone.KS_ARCH_X86, keystone.KS_MODE_64)\n",
    "            encoding, count = ks.asm(CODE)\n",
    "            print(\"%s = %s (number of statements: %u)\" %(CODE, encoding, count))\n",
    "\n",
    "        except keystone.KsError as e:\n",
    "            print(\"ERROR: %s\" %e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParseInsn:\n",
    "    cond_mapping = {\n",
    "        'eq' : 'e',\n",
    "        'ne' : 'ne',\n",
    "        'hs' : 'ae',\n",
    "        'lo' : 'b',\n",
    "        'mi' : 's',\n",
    "        'pl' : 'ns',\n",
    "        'vs' : 'o',\n",
    "        'vc' : 'no',\n",
    "        'hi' : 'a',\n",
    "        'ls' : 'be',\n",
    "        'ge' : 'ge',\n",
    "        'lt' : 'l',\n",
    "        'gt' : 'g',\n",
    "        'le' : 'le',\n",
    "    }\n",
    "\n",
    "    reg_p, register_translation = expand_rt_dict({\n",
    "        'x0' : 'rdi',\n",
    "        'x1' : 'rsi',\n",
    "        'x2' : 'rdx',\n",
    "        'x3' : 'rcx',\n",
    "        'x4' : 'r8',\n",
    "        'x5' : 'r9',\n",
    "        'x9' : 'rax',\n",
    "        'x10' : 'r10',\n",
    "        'x29' : 'rbp',\n",
    "        'x19' : 'rbx',\n",
    "        'x20' : 'r12',\n",
    "        'x21' : 'r13',\n",
    "        'x22' : 'r14',\n",
    "        'x23' : 'r15',\n",
    "        'sp' : 'rsp',\n",
    "    })\n",
    "\n",
    "    str_p = r'([#a-z0-9]+)'\n",
    "    hex_p = r'#([xa-f0-9]+)'\n",
    "\n",
    "    @staticmethod\n",
    "    def isreg64(reg):\n",
    "        return reg[0] == 'x' or reg[0] == 's'\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_sizeq(reg):\n",
    "        if ParseInsn.isreg64(reg):\n",
    "            return 'qword_ptr'\n",
    "        else:\n",
    "            return 'dword_ptr'\n",
    "\n",
    "    @staticmethod\n",
    "    def is_reg(str):\n",
    "        return re.compile(ParseInsn.reg_p).search(str)\n",
    "\n",
    "    @staticmethod\n",
    "    def parse(insn, rela = None):\n",
    "        if insn.mnemonic[:2] == 'b.':\n",
    "            return ParseInsn.bcond(insn, insn.mnemonic[2:], rela)\n",
    "        else:\n",
    "            handle_fun = getattr(ParseInsn, insn.mnemonic)\n",
    "            return handle_fun(insn, rela)\n",
    "\n",
    "    @staticmethod\n",
    "    def ldr(insn : capstone.CsInsn, rela : dict[int, Rela] = None):\n",
    "        ptn = f'{ParseInsn.reg_p}, ' \n",
    "        ptn += rf'\\[{ParseInsn.reg_p}, {ParseInsn.hex_p}\\]'\n",
    "        ptn = re.compile(ptn)\n",
    "\n",
    "        reg1, reg2, op2d = ptn.search(insn.op_str).groups()\n",
    "\n",
    "        op1 = ParseInsn.register_translation[reg1]\n",
    "        op2b = ParseInsn.register_translation[reg2]\n",
    "        sq = ParseInsn.get_sizeq(reg1)\n",
    "\n",
    "        return f'mov {op1}, {sq} [{op2b} + {op2d}]\\n'\n",
    "\n",
    "    @staticmethod\n",
    "    def str(insn : capstone.CsInsn, rela : dict[int, Rela] = None):\n",
    "        ptn = f'{ParseInsn.reg_p}, ' \n",
    "        ptn += rf'\\[{ParseInsn.reg_p}, {ParseInsn.hex_p}\\]'\n",
    "        ptn = re.compile(ptn)\n",
    "\n",
    "        reg1, reg2, op2d = ptn.search(insn.op_str).groups()\n",
    "\n",
    "        op1 = ParseInsn.register_translation[reg1]\n",
    "        op2b = ParseInsn.register_translation[reg2]\n",
    "        sq = ParseInsn.get_sizeq(reg1)\n",
    "\n",
    "        return f'mov {sq} [{op2b} + {op2d}], {op1}\\n'\n",
    "\n",
    "    @staticmethod\n",
    "    def adrp(insn : capstone.CsInsn, rela : dict[int, Rela] = None):\n",
    "        ptn = f'{ParseInsn.reg_p}, ' \n",
    "        ptn += rf'{ParseInsn.hex_p}'\n",
    "        ptn = re.compile(ptn)\n",
    "\n",
    "        reg1, _ = ptn.search(insn.op_str).groups()\n",
    "\n",
    "        # rela[insn.address].print()\n",
    "        rela[insn.address].overwrite_rela(type = 'R_AMD64_32')\n",
    "\n",
    "        op1 = ParseInsn.register_translation[reg1]\n",
    "\n",
    "        # the displacement forces the assembler to use a 32-bit immediate; it is relocated\n",
    "        ret = f'lea {op1}, [rip + 0x7fffffff]\\n' \n",
    "\n",
    "        # set 12 lowest bits to 0\n",
    "        ret += f'and {op1}, ~0xfff\\n' \n",
    "\n",
    "        return ret\n",
    "\n",
    "    @staticmethod\n",
    "    def mov_or_cmp(insn : capstone.CsInsn, op_name, rela = None):\n",
    "        ptn = f'{ParseInsn.reg_p}, ' \n",
    "        ptn = re.compile(ptn + rf'{ParseInsn.str_p}')\n",
    "\n",
    "        op1, op2 = ptn.search(insn.op_str).groups()\n",
    "        op1 = ParseInsn.register_translation[op1]\n",
    "\n",
    "        if ParseInsn.is_reg(op2):\n",
    "            op2 = ParseInsn.register_translation[op2]\n",
    "        else:\n",
    "            op2 = op2[1:]\n",
    "\n",
    "        return f'{op_name} {op1}, {op2}\\n'\n",
    "\n",
    "    @staticmethod\n",
    "    def mov(insn, rela = None):\n",
    "        return ParseInsn.mov_or_cmp(insn, 'mov', rela)\n",
    "\n",
    "    @staticmethod\n",
    "    def cmp(insn, rela = None):\n",
    "        return ParseInsn.mov_or_cmp(insn, 'cmp', rela)\n",
    "\n",
    "    @staticmethod\n",
    "    def add(insn : capstone.CsInsn, rela : dict[int, Rela] = None):\n",
    "        ptn = f'{ParseInsn.reg_p}, ' \n",
    "        ptn += f'{ParseInsn.reg_p}, ' \n",
    "        ptn = re.compile(ptn + rf'{ParseInsn.str_p}')\n",
    "\n",
    "        op1_old, op2, op3 = ptn.search(insn.op_str).groups()\n",
    "        op1 = ParseInsn.register_translation[op1_old]\n",
    "        op2 = ParseInsn.register_translation[op2]\n",
    "\n",
    "        has_rela = insn.address in rela.keys() \n",
    "        if ParseInsn.is_reg(op3):\n",
    "            op3 = ParseInsn.register_translation[op3]\n",
    "            if has_rela:\n",
    "                rela[insn.address].overwrite_rela(type = 'R_AMD64_32')\n",
    "        else:\n",
    "            op3 = op3[1:]\n",
    "\n",
    "        if op1 == op2:\n",
    "            return f'add {op1}, {op3}\\n'\n",
    "        elif op1 == op3:\n",
    "            return f'add {op1}, {op2}\\n'\n",
    "        elif has_rela:\n",
    "            tmp = 'r11' if ParseInsn.isreg64(op1_old) else 'r11d'\n",
    "            ret = f'mov {tmp}, 0x7fffffff\\n' # the immediate is relocated\n",
    "            ret += f'and {tmp}, 0xfff\\n'\n",
    "            return ret + f'add {op1}, {tmp}\\n'\n",
    "        else:\n",
    "            ret = f'mov {op1}, {op2}\\n'       \n",
    "            return ret + f'add {op1}, {op3}\\n'       \n",
    "\n",
    "    @staticmethod\n",
    "    def bl(insn : capstone.CsInsn, rela : dict[int, Rela] = None):\n",
    "        rela[insn.address].overwrite_rela(type = 'R_AMD64_PC32')\n",
    "\n",
    "        # the offset is relocated\n",
    "        ret = 'call 7fffffff\\n' \n",
    "        # put the return value in the register to which x0 maps'\n",
    "        ret += 'mov rdi, rax\\n'\n",
    "        return ret\n",
    "    \n",
    "    @staticmethod\n",
    "    def b(insn : capstone.CsInsn, rela : dict[int, Rela] = None):\n",
    "        ptn = re.compile(f'{ParseInsn.hex_p}')\n",
    "\n",
    "        imm = ptn.search(insn.op_str).groups()\n",
    "\n",
    "        return f'jmp {imm}\\n'\n",
    "    \n",
    "    @staticmethod\n",
    "    def bcond(insn : capstone.CsInsn, cond, rela : dict[int, Rela] = None):\n",
    "        ptn = re.compile(f'{ParseInsn.hex_p}')\n",
    "\n",
    "        imm = ptn.search(insn.op_str).groups()\n",
    "        cond = ParseInsn.cond_mapping[cond]\n",
    "\n",
    "        return f'j{cond} {imm}\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElfFile:\n",
    "    data = None\n",
    "\n",
    "    section_headers = []\n",
    "    symbols = []\n",
    "    rela_dict = {}\n",
    "\n",
    "    shstroff = None\n",
    "    sh_dict = {}\n",
    "\n",
    "    def setup(file_path):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            ElfFile.data = f.read()\n",
    "\n",
    "    def read_elf_header():\n",
    "        ElfHeader.read_elf_header()\n",
    "\n",
    "    def find_string(relative_offset, sh_string = False):\n",
    "        str_offset = relative_offset\n",
    "\n",
    "        if sh_string:\n",
    "            str_offset += ElfFile.shstroff \n",
    "        else:\n",
    "            str_offset += ElfFile.sh_dict['.strtab'].get('sh_offset')\n",
    "\n",
    "        str_end = ElfFile.data.find(b'\\x00', str_offset)\n",
    "        str_len = str_end - str_offset\n",
    "\n",
    "        str = struct.unpack(f'{str_len}s', ElfFile.data[str_offset : str_end])[0]\n",
    "\n",
    "        return str\n",
    "        \n",
    "    def read_section_headers(verbose = False):\n",
    "        for i in range(ElfHeader.get('e_shnum')):\n",
    "            offset = ElfHeader.get('e_shoff') + i * ElfHeader.get('e_shentsize')\n",
    "\n",
    "            ElfFile.section_headers += [SectionHeader(offset)]\n",
    "        \n",
    "        shstrns = ElfFile.section_headers[ElfHeader.get('e_shstrndx')]\n",
    "        ElfFile.shstroff = shstrns.get('sh_offset')\n",
    "\n",
    "        null_sh = ElfFile.section_headers[0]\n",
    "\n",
    "        for i in range(len(ElfFile.section_headers)):\n",
    "            sh = ElfFile.section_headers[i]\n",
    "            sh.set_name()\n",
    "\n",
    "            decoded_name = sh.name.decode('utf-8')\n",
    "            ElfFile.sh_dict[decoded_name] = sh\n",
    "\n",
    "            if SectionHeader.delete_pattern.search(decoded_name):\n",
    "                ElfFile.section_headers[i] = null_sh\n",
    "\n",
    "            if verbose:\n",
    "                ElfFile.section_headers[i].print()\n",
    "\n",
    "    def read_symbols():\n",
    "        sym_sh = ElfFile.sh_dict['.symtab']\n",
    "        ElfFile.symbols = Sym.collect_sym_entries(sym_sh)\n",
    "\n",
    "    def read_rela():\n",
    "        for sh in ElfFile.section_headers:\n",
    "            if (sh.type == 'SHT_RELA'):\n",
    "                rela_entries = Rela.collect_rela_entries(sh)\n",
    "                ElfFile.rela_dict[sh.name] = rela_entries\n",
    "            \n",
    "    def look_for_section(name):\n",
    "        for sh in ElfFile.section_headers:\n",
    "            if sh.name == name:\n",
    "                return sh\n",
    "\n",
    "    def find_code_sections():\n",
    "        for s in ElfFile.symbols:\n",
    "            if s.type == 'STT_FUNC': \n",
    "                sh = ElfFile.section_headers[s.get('st_shndx')]\n",
    "\n",
    "                offset = s.get('st_value')\n",
    "                code = sh.section_data[offset : offset + s.get('st_size')]\n",
    "\n",
    "                rela_name = b'.rela' + sh.name\n",
    "                exists = rela_name in ElfFile.rela_dict.keys()\n",
    "                rela = ElfFile.rela_dict[rela_name] if exists else None\n",
    "                \n",
    "                if p_shift := Translator.count_functions(code):\n",
    "                    code_x86 = Translator.translate_code(code, p_shift, rela)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0x8:\tstr\tw0, [sp, #0x1c]\n",
      "mov dword_ptr [rsp + 0x1c], edi\n",
      "\n",
      "0xc:\tstr\tw1, [sp, #0x18]\n",
      "mov dword_ptr [rsp + 0x18], esi\n",
      "\n",
      "0x10:\tldr\tw1, [sp, #0x1c]\n",
      "mov esi, dword_ptr [rsp + 0x1c]\n",
      "\n",
      "0x14:\tldr\tw0, [sp, #0x18]\n",
      "mov edi, dword_ptr [rsp + 0x18]\n",
      "\n",
      "0x18:\tadd\tw0, w1, w0\n",
      "add edi, esi\n",
      "\n",
      "0x1c:\tstr\tw0, [sp, #0x2c]\n",
      "mov dword_ptr [rsp + 0x2c], edi\n",
      "\n",
      "0x20:\tldr\tw0, [sp, #0x1c]\n",
      "mov edi, dword_ptr [rsp + 0x1c]\n",
      "\n",
      "55834574848\n",
      "2\n",
      "55834574850\n",
      "0x24:\tbl\t#0x24\n",
      "call 7fffffff\n",
      "mov rdi, rax\n",
      "\n",
      "21474836480\n",
      "10\n",
      "21474836490\n",
      "0x28:\tadrp\tx0, #0\n",
      "lea rdi, [rip + 0x7fffffff]\n",
      "and rdi, ~0xfff\n",
      "\n",
      "0x2c:\tadd\tx0, x0, #0\n",
      "add rdi, 0\n",
      "\n",
      "60129542144\n",
      "2\n",
      "60129542146\n",
      "0x30:\tbl\t#0x30\n",
      "call 7fffffff\n",
      "mov rdi, rax\n",
      "\n",
      "0x34:\tldr\tw0, [sp, #0x18]\n",
      "mov edi, dword_ptr [rsp + 0x18]\n",
      "\n",
      "55834574848\n",
      "2\n",
      "55834574850\n",
      "0x38:\tbl\t#0x38\n",
      "call 7fffffff\n",
      "mov rdi, rax\n",
      "\n",
      "21474836480\n",
      "10\n",
      "21474836490\n",
      "0x3c:\tadrp\tx0, #0\n",
      "lea rdi, [rip + 0x7fffffff]\n",
      "and rdi, ~0xfff\n",
      "\n",
      "0x40:\tadd\tx0, x0, #0\n",
      "add rdi, 0\n",
      "\n",
      "60129542144\n",
      "2\n",
      "60129542146\n",
      "0x44:\tbl\t#0x44\n",
      "call 7fffffff\n",
      "mov rdi, rax\n",
      "\n",
      "0x48:\tldr\tw0, [sp, #0x2c]\n",
      "mov edi, dword_ptr [rsp + 0x2c]\n",
      "\n",
      "55834574848\n",
      "2\n",
      "55834574850\n",
      "0x4c:\tbl\t#0x4c\n",
      "call 7fffffff\n",
      "mov rdi, rax\n",
      "\n",
      "21474836480\n",
      "10\n",
      "21474836490\n",
      "0x50:\tadrp\tx0, #0\n",
      "lea rdi, [rip + 0x7fffffff]\n",
      "and rdi, ~0xfff\n",
      "\n",
      "0x54:\tadd\tx0, x0, #0\n",
      "add rdi, 0\n",
      "\n",
      "60129542144\n",
      "2\n",
      "60129542146\n",
      "0x58:\tbl\t#0x58\n",
      "call 7fffffff\n",
      "mov rdi, rax\n",
      "\n",
      "0x5c:\tldr\tw0, [sp, #0x2c]\n",
      "mov edi, dword_ptr [rsp + 0x2c]\n",
      "\n",
      "r_offset: 36\n",
      "r_info: 55834574850\n",
      "r_addend: 0\n",
      "self.sym=13\n",
      "self.type='R_AMD64_PC32'\n",
      "r_offset: 40\n",
      "r_info: 21474836490\n",
      "r_addend: 0\n",
      "self.sym=5\n",
      "self.type='R_AMD64_32'\n",
      "r_offset: 44\n",
      "r_info: 21474836757\n",
      "r_addend: 0\n",
      "self.sym=5\n",
      "self.type='R_AARCH64_ADD_ABS_LO12_NC'\n",
      "r_offset: 48\n",
      "r_info: 60129542146\n",
      "r_addend: 0\n",
      "self.sym=14\n",
      "self.type='R_AMD64_PC32'\n",
      "r_offset: 56\n",
      "r_info: 55834574850\n",
      "r_addend: 0\n",
      "self.sym=13\n",
      "self.type='R_AMD64_PC32'\n",
      "r_offset: 60\n",
      "r_info: 21474836490\n",
      "r_addend: 8\n",
      "self.sym=5\n",
      "self.type='R_AMD64_32'\n",
      "r_offset: 64\n",
      "r_info: 21474836757\n",
      "r_addend: 8\n",
      "self.sym=5\n",
      "self.type='R_AARCH64_ADD_ABS_LO12_NC'\n",
      "r_offset: 68\n",
      "r_info: 60129542146\n",
      "r_addend: 0\n",
      "self.sym=14\n",
      "self.type='R_AMD64_PC32'\n",
      "r_offset: 76\n",
      "r_info: 55834574850\n",
      "r_addend: 0\n",
      "self.sym=13\n",
      "self.type='R_AMD64_PC32'\n",
      "r_offset: 80\n",
      "r_info: 21474836490\n",
      "r_addend: 16\n",
      "self.sym=5\n",
      "self.type='R_AMD64_32'\n",
      "r_offset: 84\n",
      "r_info: 21474836757\n",
      "r_addend: 16\n",
      "self.sym=5\n",
      "self.type='R_AARCH64_ADD_ABS_LO12_NC'\n",
      "r_offset: 88\n",
      "r_info: 60129542146\n",
      "r_addend: 0\n",
      "self.sym=14\n",
      "self.type='R_AMD64_PC32'\n"
     ]
    }
   ],
   "source": [
    "input = 'test-aarch64.o'  \n",
    "output = 'out.o'\n",
    "good_output = 'test-aarch64-x64.o'  \n",
    "\n",
    "shutil.copy(input, output)\n",
    "\n",
    "ElfFile.setup(input)\n",
    "ElfFile.read_elf_header()\n",
    "ElfFile.read_section_headers()\n",
    "ElfFile.read_symbols()\n",
    "ElfFile.read_rela()\n",
    "ElfFile.find_code_sections()\n",
    "\n",
    "# print(Sym.sttsym.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
